import pandas as pd
import sys
import ast
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
sys.stdout.reconfigure(encoding='utf-8')
import os
import pickle

# ===========================
# 1. ƒê·ªçc d·ªØ li·ªáu
# ===========================
movies = pd.read_csv('data/tmdb_5000_movies.csv')
credits = pd.read_csv('data/tmdb_5000_credits.csv')
mcredit = pd.merge(movies, credits, left_on="id", right_on="movie_id")

def Convert(obj):
    try:
        return [i['name'] for i in ast.literal_eval(obj)]
    except:
        return []

def get_director(obj):
    try:
        for i in ast.literal_eval(obj):
            if i['job'] == 'Director':
                return i['name']
        return ""
    except:
        return ""

mcredit['genres'] = mcredit['genres'].apply(Convert)
mcredit['keywords'] = mcredit['keywords'].apply(Convert)
mcredit['cast'] = mcredit['cast'].apply(Convert)
mcredit['crew'] = mcredit['crew'].apply(Convert)
mcredit['overview'] = mcredit['overview'].fillna("").apply(lambda x: x.split())
mcredit['title'] = mcredit['original_title']

# ===========================
# 2. Chu·∫©n b·ªã text k·∫øt h·ª£p
# ===========================
def combine_text(row):
    return f"{' '.join(row['genres'])} {' '.join(row['keywords'])} {' '.join(row['cast'])} {' '.join(row['crew'])} {' '.join(row['overview'])}"

mcredit['combined_features'] = mcredit.apply(combine_text, axis=1)

# ===========================
# 3. T·∫°o ho·∫∑c t·∫£i Cache Embedding
# ===========================
CACHE_EMB_FILE = "embeddings_cache.pkl"
CACHE_TEXT_FILE = "combined_features_cache.pkl"

# Load model
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

if os.path.exists(CACHE_EMB_FILE) and os.path.exists(CACHE_TEXT_FILE):
    print("üîπ T·∫£i embeddings t·ª´ cache...")
    with open(CACHE_EMB_FILE, "rb") as f:
        embeddings = pickle.load(f)
    with open(CACHE_TEXT_FILE, "rb") as f:
        cached_texts = pickle.load(f)

    # Ki·ªÉm tra n·∫øu d·ªØ li·ªáu kh√¥ng thay ƒë·ªïi
    if list(mcredit['combined_features']) != cached_texts:
        print("‚ö†Ô∏è Dataset thay ƒë·ªïi! T·∫°o l·∫°i embeddings...")
        embeddings = model.encode(mcredit['combined_features'], show_progress_bar=True)
        with open(CACHE_EMB_FILE, "wb") as f:
            pickle.dump(embeddings, f)
        with open(CACHE_TEXT_FILE, "wb") as f:
            pickle.dump(list(mcredit['combined_features']), f)
else:
    print("üõ† L·∫ßn ƒë·∫ßu ch·∫°y - t·∫°o embeddings v√† l∆∞u cache...")
    embeddings = model.encode(mcredit['combined_features'], show_progress_bar=True)
    with open(CACHE_EMB_FILE, "wb") as f:
        pickle.dump(embeddings, f)
    with open(CACHE_TEXT_FILE, "wb") as f:
        pickle.dump(list(mcredit['combined_features']), f)

print("‚úÖ Embeddings ƒë√£ s·∫µn s√†ng!")

# ===========================
# 4. H√†m recommend
# ===========================
def recommend_movie(user_description, top_n=5):
    user_vec = model.encode([user_description])
    sim_scores = cosine_similarity(user_vec, embeddings)[0]
    top_indices = np.argsort(sim_scores)[::-1][:top_n]
    
    print("\nüîç G·ª£i √Ω phim ph√π h·ª£p v·ªõi m√¥ t·∫£:")
    for idx in top_indices:
        print(f"- üé¨ {mcredit['title'].iloc[idx]}  (Similarity: {sim_scores[idx]:.4f})")
    
    return mcredit['title'].iloc[top_indices].values

# ===========================
# 5. Test
# ===========================
while True:
    user_input=str(input('Nh·∫≠p m√¥ t·∫£ c·ªßa b·∫°n(n·∫øu mu·ªën d·ª´ng, nh·∫≠p "end") : '))
    if(user_input=="end"):
        break
    try:
        top_n=int(input('B·∫°n mu·ªën g·ª£i √Ω bao nhi√™u b·ªô phim(int) :'))
        recommend_movie(user_input,top_n)
    except:
        raise ValueError('H√£y nh·∫≠p ƒë√∫ng s·ªë nguy√™n!')



#user_input_vi = "m·ªôt b·ªô phim h√†nh ƒë·ªông c√≥ y·∫øu t·ªë khoa h·ªçc vi·ªÖn t∆∞·ªüng v√† cu·ªôc chi·∫øn ch·ªëng qu√°i v·∫≠t"
#recommend_movie(user_input_vi, top_n=5)

#user_input_en = "a sci-fi movie with time travel and a hero saving humanity"
#recommend_movie(user_input_en, top_n=5)
